

<!DOCTYPE html>
<html lang="zh-Hans" color-mode=light>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Scrapy爬虫（1）-爬取知乎用户信息 - So1n blog</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />
  
  <meta name="description" content="阅读scrapy后做了一个简单的scrapy爬虫


...">
  <meta name="author" content="So1n">
  <link rel="icon" href="/images/icons/favicon.ico" type="image/png" sizes="16x16">
  <link rel="icon" href="/images/icons/favicon.ico" type="image/png" sizes="32x32">
  <link rel="apple-touch-icon" href="/images/icons/favicon.ico" sizes="180x180">
  <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon.ico">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1445822_s6x2xcokxrl.css">

  

  
    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css">

  

  
    
      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/atom-one-dark.min.css" name="highlight-style" mode="light">

      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/atom-one-dark.min.css" name="highlight-style" mode="dark">

      
  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      isHome: false,
      fancybox: true,
      pjax: false,
      lazyload: {
        enable: true,
        only_post: 'false',
        loading: '/images/theme/loading.gif'
      },
      donate: {
        enable: true,
        alipay: 'https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/4d2ebf32586d8799ee2e75333d6f5d2.jpg?raw=true',
        wechat: ''
      },
      galleries: {
        enable: true
      },
      fab: {
        enable: true,
        always_show: true
      },
      carrier: {
        enable: false
      },
      daovoice: {
        enable: false
      },
      preview: {
        background: {
          default: '/images/theme/welcome-image.jpg',
          api: 'https://source.unsplash.com/random/1920x1080'
        },
        motto: {
          default: '我们总说社会是个大染缸 其实是我们自己掉色',
          api: '',
          data_contents: '["data","content"]'
        },
      },
      qrcode: {
        enable: true,
        type: 'url',
        image: 'https://pic.izhaoo.com/weapp-code.jpg',
      },
      toc: {
        enable: true
      },
      scrollbar: {
        type: 'simple'
      },
      notification: {
        enable: false,
        delay: 4500,
        list: '',
        page_white_list: '',
        page_black_list: ''
      }
    }
  </script>

  

  

<meta name="generator" content="Hexo 5.3.0"></head>

<body class="lock-screen">
  <div class="loading"></div>
  


  <nav class="navbar">
    <div class="left">
      
        <i class="iconfont iconqrcode j-navbar-qrcode"></i>
      
      
        <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i>
      
    </div>
    <div class="center">Scrapy爬虫（1）-爬取知乎用户信息</div>
    <div class="right">
      <i class="iconfont iconmenu j-navbar-menu"></i>
    </div>
    
      <div id="qrcode-navbar"></div>
    
  </nav>

  

<nav class="menu">
  <div class="menu-wrap">
    <div class="menu-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <ul class="menu-content"><li class="menu-item">
        <a href="/ " class="underline "> 首页</a>
      </li><li class="menu-item">
        <a href="/galleries/ " class="underline "> 摄影</a>
      </li><li class="menu-item">
        <a target="_blank" rel="noopener" href="http://so1nz.lofter.com/ " class="underline "> 时光</a>
      </li><li class="menu-item">
        <a href="/archives/ " class="underline "> 归档</a>
      </li><li class="menu-item">
        <a href="/tags/ " class="underline "> 标签</a>
      </li><li class="menu-item">
        <a href="/categories/ " class="underline "> 分类</a>
      </li><li class="menu-item">
        <a href="/about/ " class="underline "> 关于</a>
      </li></ul>
    
      <div class="menu-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
    
  </div>
</nav>
  <main id="main">
  <div class="article-wrap">
    <div class="row container">
      <div class="col-xl-3"></div>
      <div class="col-xl-6"><article class="article">
  <div class="wrap">
    <section class="head">
  <img   class="lazyload" data-original="/images/theme/post-image.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">Scrapy爬虫（1）-爬取知乎用户信息</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>August 23, 2017</span>
      
      本文总阅读量<span id="busuanzi_value_page_pv"></span>次
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>15565</span>
    </div>
  </div>
</section>

    <section class="main">
      <section class="content">
        <h2 id="Scrapy爬虫（1）-知乎"><a href="#Scrapy爬虫（1）-知乎" class="headerlink" title="Scrapy爬虫（1）-知乎"></a>Scrapy爬虫（1）-知乎</h2><p>第一次用Scrap创建的爬虫，详细记录下<br>完整代码请访问<a target="_blank" rel="noopener" href="https://github.com/so1n/learn-python/tree/master/6-zhihuSpider">这里</a>,不过代码可能有所不同</p>
<h3 id="1-前记"><a href="#1-前记" class="headerlink" title="-1.前记"></a>-1.前记</h3><p>本来是昨天弄好代码，今天写文章的。然后今天早上在逛台风吧看台风天鸽状况，天鸽近岸爆发加上机构被妮妲狼来了戏耍后都保持谨慎态度，珠海到早上上班时间后才挂红色预警，澳门则到了快登录才挂10号风球，珠三角没有做好防范，还有近岸爆发和赶上天文大潮导致受灾加重，希望那里灾情不重。付上两张图，一张是澳门海水倒灌一张是天鸽高层图，很像鸽子头<br><img    class="lazyload" data-original="https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/scrapy%E5%8F%B0%E9%A3%8E1.jpg?raw=true" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">enter description here</span><br><img    class="lazyload" data-original="https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/Scrapy%E5%8F%B0%E9%A3%8E2.jpg?raw=true" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">enter description here</span></p>
<h3 id="0-思路验证"><a href="#0-思路验证" class="headerlink" title="0.思路验证"></a>0.思路验证</h3><p>在创建这个工程前，我先用段代码来检验基本功能可否运行<br>知乎可以不用登录获取用户信息，对我来说，方便太多了，而且知乎的查看关注页面那里同时显示有个人用户信息所以直接访问：<a target="_blank" rel="noopener" href="https://www.zhihu.com/people/%EF%BC%88token%EF%BC%89/following">https://www.zhihu.com/people/（token）/following</a><br>就可以找到我要的信息了（虽然关注列表只有20个，不过无所谓）<br><img    class="lazyload" data-original="https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/%E7%9F%A5%E4%B9%8E-%E6%9F%A5%E7%9C%8B%E7%9F%A5%E4%B9%8E%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE.png?raw=true" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">enter description here</span><br>提取信息如图，直接copy这段数据去相应网站分析后，可以得出我要的数据在两个部分，<br>一个是在[‘people’][‘followingByUser’][urltoken][‘ids’]<br>另一个是在[‘entities’][‘users’][urltoken]<br>找到后就可以写代码开始爬下来了。<br>不过知乎的json会有空，比如这个用户没有学校的值时，json就没有相应的节点，如果直接爬就会报错，然后我也没有找到比较简便的处理方法，就写了try…except（如果用了对象，一个方法来复用，最后代码量也差不多，我就放弃了）<br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> requests<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">user</span>(<span class="hljs-params">urltoken</span>):</span><br>	headers = &#123;<span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;</span>&#125;<br>	url = <span class="hljs-string">&#x27;https://www.zhihu.com/people/&#x27;</span>+urltoken+<span class="hljs-string">&#x27;/following&#x27;</span><br>	html = requests.get(url, headers=headers).text<br>	soup = BeautifulSoup(html, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>	json_text = soup.body.contents[<span class="hljs-number">1</span>].attrs[<span class="hljs-string">&#x27;data-state&#x27;</span>]<br>	ob_json = json.loads(json_text)<br>	followinglist = ob_json[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-string">&#x27;followingByUser&#x27;</span>][urltoken][<span class="hljs-string">&#x27;ids&#x27;</span>]<br>	tempset = <span class="hljs-built_in">set</span>(followinglist)<br>	tempset.remove(<span class="hljs-literal">None</span>)<br>	followinglist = <span class="hljs-built_in">list</span>(tempset)<br>	user_json = ob_json[<span class="hljs-string">&#x27;entities&#x27;</span>][<span class="hljs-string">&#x27;users&#x27;</span>][urltoken]<br>	user_info = user_json[<span class="hljs-string">&#x27;headline&#x27;</span>]<br>	<span class="hljs-keyword">try</span>:<br>	    school = user_json[<span class="hljs-string">&#x27;educations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;school&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    school = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    major = user_json[<span class="hljs-string">&#x27;educations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;major&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    major = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    job = user_json[<span class="hljs-string">&#x27;employments&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;job&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    job = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    company = user_json[<span class="hljs-string">&#x27;employments&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;company&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    company = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>: <br>	    description = user_json[<span class="hljs-string">&#x27;description&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    description = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    business = user_json[<span class="hljs-string">&#x27;business&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    business = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    zhihu_name = user_json[<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    zhihu_name = <span class="hljs-string">&#x27;&#x27;</span><br>	<span class="hljs-keyword">try</span>:<br>	    location = user_json[<span class="hljs-string">&#x27;locations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>	<span class="hljs-keyword">except</span>:<br>	    location = <span class="hljs-string">&#x27;&#x27;</span><br>	gender = user_json[<span class="hljs-string">&#x27;gender&#x27;</span>]<br>	<span class="hljs-keyword">if</span> gender == <span class="hljs-number">1</span>:<br>	    gender = <span class="hljs-string">&#x27;男&#x27;</span><br>	<span class="hljs-keyword">elif</span> gender == <span class="hljs-number">0</span>:<br>	    gender = <span class="hljs-string">&#x27;女&#x27;</span><br>	<span class="hljs-keyword">else</span>:<br>	    gender = <span class="hljs-string">&#x27;未知&#x27;</span><br>	uesr_list = [user_info, job, company, description, business, zhihu_name, location, gender, school, major]<br>	print(uesr_list)<br>	<span class="hljs-keyword">return</span> followinglist<br><br><br>urltoken = <span class="hljs-string">&#x27;sgai&#x27;</span><br><span class="hljs-keyword">for</span> urltoken <span class="hljs-keyword">in</span> user(urltoken):<br>	print(user(urltoken))<br></code></pre></td></tr></table></figure>
<p>呈现的结果部分如下：</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;喜欢用数据讲故事。</span>&#x27;, <span class="hljs-symbol">&#x27;数据挖掘工程师</span>&#x27;, <span class="hljs-symbol">&#x27;物流</span>&#x27;, <span class="hljs-symbol">&#x27;有关于我的工作和生活都在微信公众号：一个程序员的日常；会接数据采集、爬虫定制、数据分析相关的单子，请直接私信我。</span>&#x27;, <span class="hljs-symbol">&#x27;互联网</span>&#x27;, <span class="hljs-symbol">&#x27;路人甲</span>&#x27;, <span class="hljs-symbol">&#x27;上海</span>&#x27;, <span class="hljs-symbol">&#x27;男</span>&#x27;, &#x27;&#x27;, &#x27;&#x27;]<br>[<span class="hljs-symbol">&#x27;不追先圣脚步，我行处，皆道路！</span>&#x27;, <span class="hljs-symbol">&#x27;二当家</span>&#x27;, <span class="hljs-symbol">&#x27;游戏公司</span>&#x27;, <span class="hljs-symbol">&#x27;此心光明，亦复何言。我已委托“维权骑士”（&lt;a</span> href=<span class="hljs-string">&quot;https://link.zhihu.com/?target=http%3A//rightknights.com&quot;</span> class=<span class="hljs-string">&quot; external&quot;</span> target=<span class="hljs-string">&quot;_blank&quot;</span> rel=<span class="hljs-string">&quot;nofollow noreferrer&quot;</span>&gt;&lt;span class=<span class="hljs-string">&quot;invisible&quot;</span>&gt;http://&lt;/span&gt;&lt;span class=<span class="hljs-string">&quot;visible&quot;</span>&gt;rightknights.com&lt;/span&gt;&lt;span class=<span class="hljs-string">&quot;invisible&quot;</span>&gt;&lt;/span&gt;&lt;i class=<span class="hljs-string">&quot;icon-external&quot;</span>&gt;&lt;/i&gt;&lt;/a&gt;）为我的文章进行维权行动&#x27;, <span class="hljs-symbol">&#x27;互联网</span>&#x27;, <span class="hljs-symbol">&#x27;断罪小学赵日天</span>&#x27;, <span class="hljs-symbol">&#x27;深圳/南京/上海</span>&#x27;, <span class="hljs-symbol">&#x27;男</span>&#x27;, &#x27;&#x27;, &#x27;&#x27;]<br>[<span class="hljs-symbol">&#x27;yang-ze-yong-3</span>&#x27;, <span class="hljs-symbol">&#x27;zhong-wen-40-43</span>&#x27;, <span class="hljs-symbol">&#x27;ni-ke-ri-xiang-ji</span>&#x27;, <span class="hljs-symbol">&#x27;miloyip</span>&#x27;, <span class="hljs-symbol">&#x27;zuo-wen-jie</span>&#x27;, <span class="hljs-symbol">&#x27;lxghost</span>&#x27;, <span class="hljs-symbol">&#x27;mukadas-kadir</span>&#x27;, <span class="hljs-symbol">&#x27;justin-99-9</span>&#x27;, <span class="hljs-symbol">&#x27;wang-ruo-shan-88</span>&#x27;, <span class="hljs-symbol">&#x27;zhaoyanbo0098</span>&#x27;, <span class="hljs-symbol">&#x27;guo-tao-45-48</span>&#x27;, <span class="hljs-symbol">&#x27;mtjj</span>&#x27;, <span class="hljs-symbol">&#x27;satanzhangdi</span>&#x27;, <span class="hljs-symbol">&#x27;wang-hong-hao-99</span>&#x27;, <span class="hljs-symbol">&#x27;bei-mang-4</span>&#x27;, <span class="hljs-symbol">&#x27;water-five</span>&#x27;, <span class="hljs-symbol">&#x27;li-ji-ren</span>&#x27;, <span class="hljs-symbol">&#x27;he-jing-92-23</span>&#x27;, <span class="hljs-symbol">&#x27;wei-lan-tian-4</span>&#x27;, <span class="hljs-symbol">&#x27;yang-da-bao-32</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;个人微信：Maekcurtain</span>&#x27;, <span class="hljs-symbol">&#x27;414632028</span>&#x27;, <span class="hljs-symbol">&#x27;UI设计交流群</span>&#x27;, &#x27;&#x27;, <span class="hljs-symbol">&#x27;互联网</span>&#x27;, <span class="hljs-symbol">&#x27;莫若</span>&#x27;, &#x27;&#x27;, <span class="hljs-symbol">&#x27;男</span>&#x27;, <span class="hljs-symbol">&#x27;微信公众号</span>&#x27;, <span class="hljs-symbol">&#x27;imui1060</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;chenqin</span>&#x27;, <span class="hljs-symbol">&#x27;xia-ji-ji-28</span>&#x27;, <span class="hljs-symbol">&#x27;yunshu</span>&#x27;, <span class="hljs-symbol">&#x27;sizhuren</span>&#x27;, <span class="hljs-symbol">&#x27;sgai</span>&#x27;, <span class="hljs-symbol">&#x27;hua-sha-94</span>&#x27;, <span class="hljs-symbol">&#x27;guahu</span>&#x27;, <span class="hljs-symbol">&#x27;sun-lin-li-72-11</span>&#x27;, <span class="hljs-symbol">&#x27;luo-pan-57</span>&#x27;, <span class="hljs-symbol">&#x27;wang-ni-ma-94</span>&#x27;, <span class="hljs-symbol">&#x27;si-tu-ying-ying-18</span>&#x27;, <span class="hljs-symbol">&#x27;zheng-gong-si</span>&#x27;, <span class="hljs-symbol">&#x27;cao-rui-ting-18</span>&#x27;, <span class="hljs-symbol">&#x27;tian-ji-shun</span>&#x27;, <span class="hljs-symbol">&#x27;ding-xiang-yi-sheng</span>&#x27;, <span class="hljs-symbol">&#x27;jue-qiang-de-nu-li</span>&#x27;, <span class="hljs-symbol">&#x27;ma-bo-yong</span>&#x27;, <span class="hljs-symbol">&#x27;xiaoxueli</span>&#x27;, <span class="hljs-symbol">&#x27;ai-an-dong-ni-tu-zi-73</span>&#x27;, <span class="hljs-symbol">&#x27;guo-zi-501</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;孤独享受者</span>&#x27;, &#x27;&#x27;, &#x27;&#x27;, <span class="hljs-symbol">&#x27;愿你梦里有喝不完的酒</span>&#x27;, &#x27;&#x27;, <span class="hljs-symbol">&#x27;奥LiVia</span>&#x27;, <span class="hljs-symbol">&#x27;北京</span>&#x27;, <span class="hljs-symbol">&#x27;女</span>&#x27;, &#x27;&#x27;, &#x27;&#x27;]<br>[<span class="hljs-symbol">&#x27;metrodatateam</span>&#x27;, <span class="hljs-symbol">&#x27;jllijlli</span>&#x27;, <span class="hljs-symbol">&#x27;zao-meng-zhe-62-62</span>&#x27;, <span class="hljs-symbol">&#x27;kaiserwang730</span>&#x27;, <span class="hljs-symbol">&#x27;olivia-60-10</span>&#x27;, <span class="hljs-symbol">&#x27;qi-e-chi-he-zhi-nan</span>&#x27;, <span class="hljs-symbol">&#x27;fandaidai</span>&#x27;, <span class="hljs-symbol">&#x27;an-cheng-98</span>&#x27;, <span class="hljs-symbol">&#x27;zhou-zuo</span>&#x27;, <span class="hljs-symbol">&#x27;yang-ru-55-52</span>&#x27;, <span class="hljs-symbol">&#x27;wang-tiao-tiao-91</span>&#x27;, <span class="hljs-symbol">&#x27;EDASP</span>&#x27;, <span class="hljs-symbol">&#x27;ma-ke-28</span>&#x27;, <span class="hljs-symbol">&#x27;shirley-shan-63</span>&#x27;, <span class="hljs-symbol">&#x27;lens-27</span>&#x27;, <span class="hljs-symbol">&#x27;mo-zhi-xian-sheng</span>&#x27;, <span class="hljs-symbol">&#x27;hu-yang-zi</span>&#x27;, <span class="hljs-symbol">&#x27;tu-si-ji-da-lao-ye</span>&#x27;, <span class="hljs-symbol">&#x27;summer-world</span>&#x27;, <span class="hljs-symbol">&#x27;liusonglin</span>&#x27;]<br>[<span class="hljs-symbol">&#x27;非正经演绎派厨艺新鲜人，公众号：餐桌奇谈</span>&#x27;, <span class="hljs-symbol">&#x27;吃货担当</span>&#x27;, <span class="hljs-symbol">&#x27;美食圈</span>&#x27;, <span class="hljs-symbol">&#x27;我有一颗馋嘴痣～~所有文章及答案均需付费转载，不允许擅自搬运~我已委托“维权骑士”（&lt;a</span> href=<span class="hljs-string">&quot;https://link.zhihu.com/?target=http%3A//rightknights.com&quot;</span> class=<span class="hljs-string">&quot; external&quot;</span> target=<span class="hljs-string">&quot;_blank&quot;</span> rel=<span class="hljs-string">&quot;nofollow noreferrer&quot;</span>&gt;&lt;span class=<span class="hljs-string">&quot;invisible&quot;</span>&gt;http://&lt;/span&gt;&lt;span class=<span class="hljs-string">&quot;visible&quot;</span>&gt;rightknights.com&lt;/span&gt;&lt;span class=<span class="hljs-string">&quot;invisible&quot;</span>&gt;&lt;/span&gt;&lt;i class=<span class="hljs-string">&quot;icon-external&quot;</span>&gt;&lt;/i&gt;&lt;/a&gt;）为我的文章进行维权行动&#x27;, <span class="hljs-symbol">&#x27;互联网</span>&#x27;, <span class="hljs-symbol">&#x27;芊芊呐小桌儿</span>&#x27;, <span class="hljs-symbol">&#x27;北京</span>&#x27;, <span class="hljs-symbol">&#x27;女</span>&#x27;, &#x27;&#x27;, &#x27;&#x27;]<br>[<span class="hljs-symbol">&#x27;feiyucz</span>&#x27;, <span class="hljs-symbol">&#x27;richard-45-75</span>&#x27;, <span class="hljs-symbol">&#x27;nusbrant</span>&#x27;, <span class="hljs-symbol">&#x27;sgai</span>&#x27;, <span class="hljs-symbol">&#x27;zhou-dong-yu-55-93</span>&#x27;, <span class="hljs-symbol">&#x27;easteregg</span>&#x27;, <span class="hljs-symbol">&#x27;cai-lan-80-17</span>&#x27;, <span class="hljs-symbol">&#x27;zhao-yu-67-63</span>&#x27;, <span class="hljs-symbol">&#x27;MrBurning</span>&#x27;, <span class="hljs-symbol">&#x27;zhouzhao</span>&#x27;, <span class="hljs-symbol">&#x27;excited-vczh</span>&#x27;, <span class="hljs-symbol">&#x27;justjavac.com</span>&#x27;, <span class="hljs-symbol">&#x27;mu-se-wan-sheng-ge</span>&#x27;, <span class="hljs-symbol">&#x27;simona-wen</span>&#x27;, <span class="hljs-symbol">&#x27;wstcbh</span>&#x27;, <span class="hljs-symbol">&#x27;BoomberLiu</span>&#x27;, <span class="hljs-symbol">&#x27;qing-yuan-zi-84</span>&#x27;, <span class="hljs-symbol">&#x27;cocokele</span>&#x27;, <span class="hljs-symbol">&#x27;hei-bai-hui-11-79</span>&#x27;, <span class="hljs-symbol">&#x27;wangxiaofeng</span>&#x27;]<br></code></pre></td></tr></table></figure>
<p>由此知道我的想法可以运行起来，所以开始创建工程</p>
<h3 id="1-创建工程"><a href="#1-创建工程" class="headerlink" title="1.创建工程"></a>1.创建工程</h3><blockquote>
<p>整个流程：从起始url中解析出用户信息，然后进入关注者界面和被关注者界面，提取关系用户ID和新的用户链接，将用户信息和关系用户ID存储到MongoDB中，将新的用户链接交给用户信息解析模块，依次类推。完成循环抓取任务</p>
</blockquote>
<p>在终端输入</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-variable">$ </span>scrapy startproject zhihuSpider<br></code></pre></td></tr></table></figure>
<p>之后会在当前目录生成以下结构</p>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs coq">zhihuSpider<br>    |<span class="hljs-type">- scrapy</span>.cfg                        项目部署文件<br>    |<span class="hljs-type">- zhihuSpider</span>                     该项目的python模块，可以在这里加入代码<br>        |<span class="hljs-type">- __init__</span>.py                 <br>        |<span class="hljs-type">- items</span>.py                       主要是将爬取的非结构性的数据源提取结构性数据<br>        |<span class="hljs-type">- middlewares</span>.py          <br>        |<span class="hljs-type">- pipelines</span>.py                  将爬取的数据进行持久化存储<br>        |<span class="hljs-type">-  __pycache__</span>  <br>        |<span class="hljs-type">-  settings</span>.py                  配置文件<br>        |<span class="hljs-type">-  spiders</span>                       放置spider代码的目录<br>            |<span class="hljs-type">-  __init__</span>.py <br>            |<span class="hljs-type">-  __pycache__</span><br></code></pre></td></tr></table></figure>
<h3 id="2-创建爬虫模块"><a href="#2-创建爬虫模块" class="headerlink" title="2.创建爬虫模块"></a>2.创建爬虫模块</h3><p>在终端输入</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vim">$ <span class="hljs-keyword">cd</span> zhihuSpider<br>$ scrapy genspider -t crawl zhihu.<span class="hljs-keyword">com</span> zhihu.<span class="hljs-keyword">com</span><br></code></pre></td></tr></table></figure>
<p>这里是用scpry的bench的genspider<br>语法是scrapy genspider[-t template] &lt;name&gt; &lt;domain&gt;<br>可以用模板来创建spider<br>之后spider文件夹下面会多出一个zhihu_com.py的文件，里面有段代码为：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">7 </span>    <span class="hljs-keyword">name</span> = <span class="hljs-comment">&#x27;zhihu.com&#x27;</span><br><span class="hljs-symbol">8 </span>    allowed_domains = [<span class="hljs-comment">&#x27;zhihu.com&#x27;]</span><br><span class="hljs-symbol">9 </span>    start_urls = [<span class="hljs-comment">&#x27;http://zhihu.com/&#x27;]</span><br><br></code></pre></td></tr></table></figure>
<p>其中<br>name是定义spider名字的字符串，它是必须且唯一的<br> allowed_domains是可选的，它包含了spider允许爬取的域名列表。当OffsiteMiddleware组件启用是，域名不在列表中的url不会被跟进<br> start_urls为url列表，当没有使用start_requests()方法配置Requests时，Spider将从该列表中开始进行爬取<br> 重新回到开头看到<br> <figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">ZhihuComSpider</span>(<span class="hljs-symbol">CrawlSpider</span>):<br></code></pre></td></tr></table></figure><br> Spider有3大类，最基本的是Spieder，他的属性有name, allowed_domains, start_urls,custom_settings,crawler,start_requests().除了Spieder外还有CrawlSpider和XMLFeedSpider。<br> CraelCpider除了从Spider继承过来的属性外，还提供了一个新的属性rules，rules是一个包含一个或多个Rule对象的集合，每个Rule对爬取网站的动作定义了特定的规则。如果多个Rule匹配了相同的链接，则根据它们在rules属性中被定义的顺序，第一个会被使用。<br> Rule类的原型为：<br> <figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">scrapy.contrib,spiders.<span class="hljs-constructor">Rule(<span class="hljs-params">link_extractor</span>,<span class="hljs-params">callback</span>=None,<span class="hljs-params">cb_kwargs</span>=None,<span class="hljs-params">follow</span>=None,<span class="hljs-params">process_links</span>=None, <span class="hljs-params">process_request</span>=None)</span><br></code></pre></td></tr></table></figure><br> 参数说明</p>
<blockquote>
<p>link_extractor 是一个LinkExtractor对象，定义了如何从爬取到的页面提取链接。<br>callback回调函数接受一个response作为一个参数，应避免使用parse作为回调函数<br>cb_kwargs包含传递给回调函数的参数的字典<br>follow是一个布尔值，指定了根据规则从respose提取的链接是否需要跟进</p>
</blockquote>
<p> 然而，知乎跳转到关注人的链接不是完整的，而是类似/perople/xxx/following的，crawlSpider没办法识别，所以不能使用rules（或者是我食用crawlSpider方法不对？我都弄了半天了）<br> 了解了这样多，结果我就直接套上去，不使用rules，因为我的链接不是从网页里面提取的，要自己创造的<br> 直接把url注释掉，因为CrawlSpider属于Spider类，所以调用parse解析就好了<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ZhihuComSpider</span>(<span class="hljs-params">CrawlSpider</span>):</span><br>   name = <span class="hljs-string">&#x27;zhihu.com&#x27;</span><br>   allowed_domains = [<span class="hljs-string">&#x27;zhihu.com&#x27;</span>]<br>   start_urls = [<span class="hljs-string">&#x27;https://www.zhihu.com/people/sgai/following&#x27;</span>]<br><br><br>   <span class="hljs-comment">#rules = (</span><br>   <span class="hljs-comment">#    Rule(LinkExtractor(allow=r&#x27;/people/(\w+)/following$&#x27;, process_value=&#x27;my_process_value&#x27;, unique=True, deny_domains=deny), callback=&#x27;parse_item&#x27;, follow=True),</span><br>   <span class="hljs-comment">#)</span><br><br><br>   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br></code></pre></td></tr></table></figure><br> 然后到setting.py下面更改3个数值<br> <figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"> 请求头<br> USER_AGENT = <span class="hljs-comment">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;</span><br>关闭robot<br>ROBOTSTXT_OBEY = <span class="hljs-literal">False</span><br>关闭cookies追踪<br>COOKIES_ENABLED = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure></p>
<h3 id="3-解析网页"><a href="#3-解析网页" class="headerlink" title="3.解析网页"></a>3.解析网页</h3><p>解析网页直接照搬我之前测试是否可以运行的代码，并进行了相对应的修改</p>
<ul>
<li>建立一个url存放列表，进行url去重</li>
<li>从网页捕获用户urltoken</li>
<li>tempset部分用户存在没有none存在的情况，捕获错误并pass</li>
<li>description部分存在有些用户含有html代码，但是我不知道怎么去除只获取中文。。。。</li>
<li>把获取的数据封装到item里面</li>
<li>判断捉取的用户列表有没有存在False（用户关注数量低于20个就会出现，由于直接返回False，所以直接用if判断）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br>        deny = []<br>        html = response.text<br>        soup = BeautifulSoup(html, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>        token = soup.find(<span class="hljs-string">&quot;a&quot;</span>,&#123;<span class="hljs-string">&quot;class&quot;</span>:<span class="hljs-string">&quot;Tabs-link&quot;</span>&#125;)<br>        pattern = <span class="hljs-string">r&#x27;e/(.+)/ac&#x27;</span><br>        urltoken = re.findall(pattern, <span class="hljs-built_in">str</span>(token))[<span class="hljs-number">0</span>]<br>        json_text = soup.body.contents[<span class="hljs-number">1</span>].attrs[<span class="hljs-string">&#x27;data-state&#x27;</span>]<br>        ob_json = json.loads(json_text)<br>        followinglist = ob_json[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-string">&#x27;followingByUser&#x27;</span>][urltoken][<span class="hljs-string">&#x27;ids&#x27;</span>]<br>        tempset = <span class="hljs-built_in">set</span>(followinglist)<br>        <span class="hljs-keyword">try</span>:<br>            tempset.remove(<span class="hljs-literal">None</span>)<br>        <span class="hljs-keyword">except</span>:<br>            <span class="hljs-keyword">pass</span><br>        followinglist = <span class="hljs-built_in">list</span>(tempset)<br>        user_json = ob_json[<span class="hljs-string">&#x27;entities&#x27;</span>][<span class="hljs-string">&#x27;users&#x27;</span>][urltoken]<br>        user_info = user_json[<span class="hljs-string">&#x27;headline&#x27;</span>]<br>        <span class="hljs-keyword">try</span>:<br>            school = user_json[<span class="hljs-string">&#x27;educations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;school&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            school = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            major = user_json[<span class="hljs-string">&#x27;educations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;major&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            major = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            job = user_json[<span class="hljs-string">&#x27;employments&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;job&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            job = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            company = user_json[<span class="hljs-string">&#x27;employments&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;company&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            company = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>: <br>            description = user_json[<span class="hljs-string">&#x27;description&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            description = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            business = user_json[<span class="hljs-string">&#x27;business&#x27;</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            business = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            zhihu_name = user_json[<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            zhihu_name = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        <span class="hljs-keyword">try</span>:<br>            location = user_json[<span class="hljs-string">&#x27;locations&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;name&#x27;</span>]<br>        <span class="hljs-keyword">except</span>:<br>            location = <span class="hljs-string">&#x27;该用户尚未填写&#x27;</span><br>        gender = user_json[<span class="hljs-string">&#x27;gender&#x27;</span>]<br>        <span class="hljs-keyword">if</span> gender == <span class="hljs-number">1</span>:<br>            gender = <span class="hljs-string">&#x27;男&#x27;</span><br>        <span class="hljs-keyword">elif</span> gender == <span class="hljs-number">0</span>:<br>            gender = <span class="hljs-string">&#x27;女&#x27;</span><br>        <span class="hljs-keyword">else</span>:<br>            gender = <span class="hljs-string">&#x27;未知&#x27;</span><br><br>        item =UserInfoItem(urltoken=urltoken,user_info=user_info, job=job, company=company, description=description, business=business, zhihu_name=zhihu_name, location=location, gender=gender, school=school, major=major) <br>        <span class="hljs-keyword">yield</span> item<br>        <span class="hljs-comment">#print(followinglist)</span><br>        <span class="hljs-keyword">for</span> following <span class="hljs-keyword">in</span> followinglist:<br>            <span class="hljs-keyword">if</span> following:<br>                url = <span class="hljs-string">&#x27;https://www.zhihu.com/people/&#x27;</span>+following+<span class="hljs-string">&#x27;/following&#x27;</span><br>            <span class="hljs-comment">#else:</span><br>                <span class="hljs-comment">#url = &#x27;https://www.zhihu.com/people/&#x27;+urltoken+&#x27;/following&#x27;</span><br><br>            <span class="hljs-keyword">if</span> url <span class="hljs-keyword">in</span> deny:<br>                <span class="hljs-keyword">pass</span><br>            <span class="hljs-keyword">else</span>:<br>                deny.append(url)    <br>                <span class="hljs-keyword">yield</span> scrapy.Request(url=url,callback=self.parse)<br><br></code></pre></td></tr></table></figure>
<h3 id="4-定义item"><a href="#4-定义item" class="headerlink" title="4.定义item"></a>4.定义item</h3>定义两个item<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> scrapy<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserInfoItem</span>(<span class="hljs-params">scrapy.Item</span>):</span><br><br>    <span class="hljs-comment">#id</span><br>    urltoken = scrapy.Field()<br>    <span class="hljs-comment">#个人简介</span><br>    user_info = scrapy.Field()<br>    <span class="hljs-comment">#姓名</span><br>    zhihu_name = scrapy.Field()<br>    <span class="hljs-comment">#居住地</span><br>    location = scrapy.Field()<br>    <span class="hljs-comment">#技术领域</span><br>    business = scrapy.Field()<br>    <span class="hljs-comment">#性别</span><br>    gender = scrapy.Field()<br>    <span class="hljs-comment">#公司</span><br>    company = scrapy.Field()<br>    <span class="hljs-comment">#职位</span><br>    job = scrapy.Field()<br>    <span class="hljs-comment">#学校</span><br>    school = scrapy.Field()<br>    <span class="hljs-comment">#教育经历</span><br>    major = scrapy.Field()<br>    <span class="hljs-comment">#简介</span><br>    description = scrapy.Field()<br><br></code></pre></td></tr></table></figure>
<h3 id="5-Pipeline"><a href="#5-Pipeline" class="headerlink" title="5.Pipeline"></a>5.Pipeline</h3>定义一个Pipeline，让scrapy把数据从item存入到mongodb数据库里面，配套设置在settings.py里面<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pymongo<br><br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ZhihuspiderPipeline</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, mongo_url, mongo_db</span>):</span><br>        self.mongo_url = mongo_url<br>        self.mongo_db = mongo_db<br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span>(<span class="hljs-params">cls, crawler</span>):</span><br>        <span class="hljs-keyword">return</span> cls(<br>            mongo_url=crawler.settings.get(<span class="hljs-string">&#x27;MONGO_URL&#x27;</span>),<br>            mongo_db=crawler.settings.get(<span class="hljs-string">&#x27;MONGO_DATABASE&#x27;</span>, <span class="hljs-string">&#x27;items&#x27;</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client = pymongo.MongoClient(self.mongo_url)<br>        self.db = self.client[self.mongo_db]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span>(<span class="hljs-params">self, spider</span>):</span><br>        self.client.close()<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span>(<span class="hljs-params">self, item, spider</span>):</span><br>    	self.db.UserInfo.insert(<span class="hljs-built_in">dict</span>(item))<br>    	<span class="hljs-keyword">return</span> item<br></code></pre></td></tr></table></figure>
<h3 id="6-其他补充"><a href="#6-其他补充" class="headerlink" title="6.其他补充"></a>6.其他补充</h3><h4 id="6-1-利用middlewares-py实现ip代理"><a href="#6-1-利用middlewares-py实现ip代理" class="headerlink" title="6.1.利用middlewares.py实现ip代理"></a>6.1.利用middlewares.py实现ip代理</h4>配到设置在settings.py里面<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomProxy</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,iplist</span>):</span><br>        self.iplist=iplist<br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span>(<span class="hljs-params">cls,crawler</span>):</span><br>        <span class="hljs-keyword">return</span> cls(crawler.settings.getlist(<span class="hljs-string">&#x27;IPLIST&#x27;</span>))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_request</span>(<span class="hljs-params">self, request, spider</span>):</span><br>        proxy = random.choice(self.iplist)<br>        request.meta[<span class="hljs-string">&#x27;proxy&#x27;</span>] =proxy<br></code></pre></td></tr></table></figure>
<h4 id="6-2setting设置"><a href="#6-2setting设置" class="headerlink" title="6.2setting设置"></a>6.2setting设置</h4>请求头添加<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">USER_AGENT</span> = &#x27;Mozilla/<span class="hljs-number">5</span>.<span class="hljs-number">0</span> (X<span class="hljs-number">11</span>; Linux x<span class="hljs-number">86</span>_<span class="hljs-number">64</span>) AppleWebKit/<span class="hljs-number">537</span>.<span class="hljs-number">36</span> (KHTML, like Gecko) Chrome/<span class="hljs-number">58</span>.<span class="hljs-number">0</span>.<span class="hljs-number">3029</span>.<span class="hljs-number">110</span> Safari/<span class="hljs-number">537</span>.<span class="hljs-number">36</span>&#x27;<br></code></pre></td></tr></table></figure>
激活item和中间件<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">DOWNLOADER_MIDDLEWARES</span> = &#123;<br>    <span class="hljs-string">&#x27;zhihuSpider.middlewares.RandomProxy&#x27;</span>:543<br>&#125;<br><br>ITEM_PIPELINES = &#123;<br>    <span class="hljs-string">&#x27;zhihuSpider.pipelines.ZhihuspiderPipeline&#x27;</span>: 300,<br>&#125;<br></code></pre></td></tr></table></figure>
激活随机爬取时间<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">AUTOTHROTTLE_ENABLED</span> = <span class="hljs-literal">True</span><br><span class="hljs-comment"># The initial download delay</span><br><span class="hljs-attr">AUTOTHROTTLE_START_DELAY</span> = <span class="hljs-number">5</span><br><span class="hljs-comment"># The maximum download delay to be set in case of high latencies</span><br><span class="hljs-attr">AUTOTHROTTLE_MAX_DELAY</span> = <span class="hljs-number">60</span><br></code></pre></td></tr></table></figure>
MONGODB配置<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">MONGO_URL</span> = <span class="hljs-string">&#x27;mongodb://localhost:27017/&#x27;</span><br><span class="hljs-attr">MONGO_DATABASE</span>=<span class="hljs-string">&#x27;zhihu&#x27;</span><br></code></pre></td></tr></table></figure>
ip代理列表<br>这个ip我是从免费代理IP拿的，测试一下ip代理是否可行，我的ip代理池捉不到什么有效 ip了- -。。。<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">IPLIST</span>=[<span class="hljs-string">&quot;https://14.112.76.235:65309&quot;</span>]<br></code></pre></td></tr></table></figure>
<h3 id="7-结果"><a href="#7-结果" class="headerlink" title="7.结果"></a>7.结果</h3>用几个数据测试一下是否有保存，要爬取全部的话还要等重新换个ip代理池<br><img    class="lazyload" data-original="https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/scrapy%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2.jpg?raw=true" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption">enter description here</span></li>
</ul>
<h3 id="7-优化与补充"><a href="#7-优化与补充" class="headerlink" title="7.优化与补充"></a>7.优化与补充</h3><ul>
<li><a target="_blank" rel="noopener" href="http://www.jianshu.com/p/63638e1b8c65">Scrapy 自定义settings–简化编写爬虫操作–加快爬虫速度</a></li>
<li><a target="_blank" rel="noopener" href="https://www.v2ex.com/t/232070">v2ex讨论《scrapy 抓取速度问题》</a><br>还有scrapyd部署和scrapyd-client部署见上一篇文章</li>
</ul>
      </section>
      <section class="extra">
        
          <ul class="copyright">
  
    <li><strong>本文作者：</strong>So1n</li>
    <li><strong>本文链接：</strong><a href="http://so1n.me/2017/08/23/13-scrapy-zhihu-easy/index.html" title="http:&#x2F;&#x2F;so1n.me&#x2F;2017&#x2F;08&#x2F;23&#x2F;13-scrapy-zhihu-easy&#x2F;index.html">http:&#x2F;&#x2F;so1n.me&#x2F;2017&#x2F;08&#x2F;23&#x2F;13-scrapy-zhihu-easy&#x2F;index.html</a></li>
    <li><strong>版权声明：</strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="BY-NC-SA" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请注明出处！</li>
  
</ul>
        
        
          <section class="donate">
  <div id="qrcode-donate">
    <img   class="lazyload" data-original="https://github.com/so1n/so1n_blog_photo/blob/master/blog_photo/4d2ebf32586d8799ee2e75333d6f5d2.jpg?raw=true" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" >
  </div>
  <div class="icon">
    <a href="javascript:;" id="alipay"><i class="iconfont iconalipay"></i></a>
    <a href="javascript:;" id="wechat"><i class="iconfont iconwechat-fill"></i></a>
  </div>
</section>
        
        
  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrapy/" rel="tag">scrapy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul> 

        
  <nav class="nav">
    <a href="/2017/08/23/14-redis/"><i class="iconfont iconleft"></i>Redis命令</a>
    <a href="/2017/08/23/p1/">基于django的博客(1)<i class="iconfont iconright"></i></a>
  </nav>

      </section>
      
        <section class="comments">
  
    <div class="btn" id="comments-btn">查看评论</div>
  
  
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<div id="gitalk" class="gitalk"></div>
<script defer src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script>
  window.onload = function () {
    var gitalk = new Gitalk({
      clientID: '59f804e526b05c378470',
      clientSecret: '36679ff697cec424936a0f7c4bcd6d2988dac28e',
      id: window.location.pathname,
      repo: 'so1n.github.io',
      owner: 'so1n',
      admin: 'so1n'
    });
    if ( true ) {
      $("#comments-btn").on("click", function () {
        $(this).hide();
        gitalk.render('gitalk');
      });
    } else {
      gitalk.render('gitalk');
    }
  }
</script>

</section>
      
    </section>
  </div>
</article></div>
      <div class="col-xl-3">
        
          
  <aside class="toc-wrap">
    <h3 class="toc-title">文章目录：</h3>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy%E7%88%AC%E8%99%AB%EF%BC%881%EF%BC%89-%E7%9F%A5%E4%B9%8E"><span class="toc-text">Scrapy爬虫（1）-知乎</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%89%8D%E8%AE%B0"><span class="toc-text">-1.前记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0-%E6%80%9D%E8%B7%AF%E9%AA%8C%E8%AF%81"><span class="toc-text">0.思路验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B"><span class="toc-text">1.创建工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB%E6%A8%A1%E5%9D%97"><span class="toc-text">2.创建爬虫模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5"><span class="toc-text">3.解析网页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%9A%E4%B9%89item"><span class="toc-text">4.定义item</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Pipeline"><span class="toc-text">5.Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%85%B6%E4%BB%96%E8%A1%A5%E5%85%85"><span class="toc-text">6.其他补充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E7%BB%93%E6%9E%9C"><span class="toc-text">7.结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%BC%98%E5%8C%96%E4%B8%8E%E8%A1%A5%E5%85%85"><span class="toc-text">7.优化与补充</span></a></li></ol></li></ol>
  </aside>

        
      </div>
    </div>
  </div>
</main>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>


<footer class="footer">
  <div class="footer-social"><a 
        href="https://github.com/so1n "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#9f7be1'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  icongithub-fill "></i>
      </a></div>
  
    <div class="footer-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
  
  <div class="footer-copyright">
    总访问量<span id="busuanzi_value_site_pv"></span>次
    访客数<span id="busuanzi_value_site_uv"></span>人次
  </div>

</footer>

  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  
  
    <div class="scrollbar j-scrollbar">
  <div class="scrollbar-current j-scrollbar-current"></div>
</div>
  
  
    
<script src="/js/color-mode.js"></script>

  
</body>

<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>



  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.lazyload/1.9.1/jquery.lazyload.min.js"></script>




  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script>






  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.qrcode/1.0/jquery.qrcode.min.js"></script>




<script src="/js/utils.js"></script>
<script src="/js/script.js"></script>







  <script>
    (function () {
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>













</html>